{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAc6V6fOiPvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2c2273f-89e7-42c7-ff98-0d1f3b0baf0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQkxNE3pUuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhbQjGd-ikcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile as zipfile\n",
        "zip_ref=zipfile.ZipFile(\"/gdrive/My Drive/train.zip\",'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAAi8EUKlwrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref.extractall(\"/tmp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRjhnWommKv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref=zipfile.ZipFile(\"/gdrive/My Drive/test.zip\",'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbvxL_h1mbtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref.extractall(\"/tmp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pu5ZnKlmx5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33b835b8-c36a-4384-9913-94a509cd78af"
      },
      "source": [
        "!ls \"/tmp/train\""
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Black-grass\t    'Common wheat'\t'Scentless Mayweed'\t      test\n",
            " Charlock\t    'Fat Hen'\t\t'Shepherds Purse'\n",
            " Cleavers\t    'Loose Silky-bent'\t'Small-flowered Cranesbill'\n",
            "'Common Chickweed'   Maize\t\t'Sugar beet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xxuj8EpnGap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMLPQzsJyyWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []\n",
        "    for dir_name in os.listdir(directory): \n",
        "        for image_file in os.listdir(directory+dir_name):\n",
        "            image = cv2.imread(directory+dir_name+r'/'+image_file)\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image,(51,51),)\n",
        "                Images.append(image)\n",
        "                Labels.append(dir_name)\n",
        "    return Images, Labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWGzJEzfzpyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images, Labels = get_images('../tmp/train/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hHQpM3RzxQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "mapping = { 'Sugar beet': 0, 'Fat Hen': 1, 'Scentless Mayweed' : 2, 'Charlock' : 3,\n",
        "           'Small-flowered Cranesbill': 4, 'Maize': 5, 'Shepherds Purse' :6, 'Common wheat': 7,\n",
        "           'Common Chickweed': 8, 'Cleavers': 9, 'Loose Silky-bent' : 10, 'Black-grass': 11 ,'test':12}\n",
        "for label in Labels:  \n",
        "    labels.append(mapping[label])\n",
        "del Labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjOaw7F8z8Fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e04d0c1-be26-4aea-eb09-f0b668549d32"
      },
      "source": [
        "Images[0].shape"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 51, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTQEmmDS0vB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images = np.reshape(Images,(-1,51,51,3))\n",
        "Labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KC22U0hPgnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUejtPM1DAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bb3f81f-792b-4cea-ad94-2bdde6e2cb43"
      },
      "source": [
        "print(\"Shape of training data: \", Images.shape)\n",
        "print(\"Shape of labels data: \", Labels.shape)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data:  (5544, 51, 51, 3)\n",
            "Shape of labels data:  (5544,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2N5skFH1H07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(Images, Labels, test_size=.2, random_state=42, stratify = Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hWAWV_3F7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train,num_classes=13)\n",
        "y_val = np_utils.to_categorical(y_val,num_classes=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fReMtl3MGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.optimizers as Optimizer\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAvgPool2D, GlobalMaxPooling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Conv2D,MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McdU586_HPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_train/=255\n",
        "x_val/=255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGM1JnFB4YtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5b15b14f-8e11-4a47-eee7-82d4d2f22ff0"
      },
      "source": [
        "input_shape = (51,51,3)\n",
        "model = Sequential() \n",
        "model.add(Conv2D(256, kernel_size=(6, 6), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(75, activation='relu'))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 46, 46, 256)       27904     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 23, 23, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 21, 21, 128)       295040    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 400)               5120400   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 75)                15075     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 13)                988       \n",
            "=================================================================\n",
            "Total params: 5,539,607\n",
            "Trainable params: 5,539,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eqmRVlE5wOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycHQHGK36fqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "773e8b82-61ef-41d7-b67c-4e8f5930ff0f"
      },
      "source": [
        "batch_size=100\n",
        "epochs = 150\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val),callbacks=[])\n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4435 samples, validate on 1109 samples\n",
            "Epoch 1/150\n",
            "4435/4435 [==============================] - 2s 430us/step - loss: 0.9509 - acc: 0.6731 - val_loss: 1.1085 - val_acc: 0.6141\n",
            "Epoch 2/150\n",
            "4435/4435 [==============================] - 2s 415us/step - loss: 0.9312 - acc: 0.6760 - val_loss: 1.1085 - val_acc: 0.6123\n",
            "Epoch 3/150\n",
            "4435/4435 [==============================] - 2s 415us/step - loss: 0.9216 - acc: 0.6731 - val_loss: 1.1381 - val_acc: 0.6069\n",
            "Epoch 4/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.9177 - acc: 0.6679 - val_loss: 1.1011 - val_acc: 0.6267\n",
            "Epoch 5/150\n",
            "4435/4435 [==============================] - 2s 415us/step - loss: 0.9079 - acc: 0.6715 - val_loss: 1.1762 - val_acc: 0.6023\n",
            "Epoch 6/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.9129 - acc: 0.6762 - val_loss: 1.0826 - val_acc: 0.6276\n",
            "Epoch 7/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.8892 - acc: 0.6893 - val_loss: 1.6529 - val_acc: 0.4554\n",
            "Epoch 8/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.9137 - acc: 0.6791 - val_loss: 1.1600 - val_acc: 0.5924\n",
            "Epoch 9/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.8760 - acc: 0.6918 - val_loss: 1.1816 - val_acc: 0.6050\n",
            "Epoch 10/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.8564 - acc: 0.6943 - val_loss: 1.1657 - val_acc: 0.6087\n",
            "Epoch 11/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.8410 - acc: 0.7035 - val_loss: 1.0634 - val_acc: 0.6456\n",
            "Epoch 12/150\n",
            "4435/4435 [==============================] - 2s 424us/step - loss: 0.8360 - acc: 0.7015 - val_loss: 1.0660 - val_acc: 0.6366\n",
            "Epoch 13/150\n",
            "4435/4435 [==============================] - 2s 425us/step - loss: 0.8204 - acc: 0.7114 - val_loss: 1.1011 - val_acc: 0.6348\n",
            "Epoch 14/150\n",
            "4435/4435 [==============================] - 2s 428us/step - loss: 0.8230 - acc: 0.7048 - val_loss: 1.0930 - val_acc: 0.6213\n",
            "Epoch 15/150\n",
            "4435/4435 [==============================] - 2s 431us/step - loss: 0.8198 - acc: 0.7094 - val_loss: 1.2650 - val_acc: 0.5771\n",
            "Epoch 16/150\n",
            "4435/4435 [==============================] - 2s 428us/step - loss: 0.8015 - acc: 0.7188 - val_loss: 1.2865 - val_acc: 0.5537\n",
            "Epoch 17/150\n",
            "4435/4435 [==============================] - 2s 428us/step - loss: 0.8171 - acc: 0.7134 - val_loss: 1.0722 - val_acc: 0.6195\n",
            "Epoch 18/150\n",
            "4435/4435 [==============================] - 2s 428us/step - loss: 0.7866 - acc: 0.7209 - val_loss: 1.3415 - val_acc: 0.5888\n",
            "Epoch 19/150\n",
            "4435/4435 [==============================] - 2s 427us/step - loss: 0.7883 - acc: 0.7218 - val_loss: 1.1254 - val_acc: 0.5996\n",
            "Epoch 20/150\n",
            "4435/4435 [==============================] - 2s 424us/step - loss: 0.7866 - acc: 0.7193 - val_loss: 1.0431 - val_acc: 0.6384\n",
            "Epoch 21/150\n",
            "4435/4435 [==============================] - 2s 425us/step - loss: 0.7685 - acc: 0.7200 - val_loss: 1.0674 - val_acc: 0.6402\n",
            "Epoch 22/150\n",
            "4435/4435 [==============================] - 2s 423us/step - loss: 0.7776 - acc: 0.7218 - val_loss: 1.1063 - val_acc: 0.6375\n",
            "Epoch 23/150\n",
            "4435/4435 [==============================] - 2s 424us/step - loss: 0.7506 - acc: 0.7362 - val_loss: 1.1605 - val_acc: 0.6132\n",
            "Epoch 24/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.7363 - acc: 0.7409 - val_loss: 1.1033 - val_acc: 0.6339\n",
            "Epoch 25/150\n",
            "4435/4435 [==============================] - 2s 424us/step - loss: 0.7434 - acc: 0.7418 - val_loss: 1.0877 - val_acc: 0.6294\n",
            "Epoch 26/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.7418 - acc: 0.7328 - val_loss: 1.0365 - val_acc: 0.6555\n",
            "Epoch 27/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.7305 - acc: 0.7342 - val_loss: 1.0315 - val_acc: 0.6537\n",
            "Epoch 28/150\n",
            "4435/4435 [==============================] - 2s 423us/step - loss: 0.7416 - acc: 0.7326 - val_loss: 1.1125 - val_acc: 0.6249\n",
            "Epoch 29/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.7264 - acc: 0.7427 - val_loss: 1.0562 - val_acc: 0.6420\n",
            "Epoch 30/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.7030 - acc: 0.7565 - val_loss: 1.0576 - val_acc: 0.6465\n",
            "Epoch 31/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.6946 - acc: 0.7497 - val_loss: 1.0741 - val_acc: 0.6519\n",
            "Epoch 32/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.6873 - acc: 0.7517 - val_loss: 1.2012 - val_acc: 0.6186\n",
            "Epoch 33/150\n",
            "4435/4435 [==============================] - 2s 416us/step - loss: 0.6791 - acc: 0.7621 - val_loss: 1.0785 - val_acc: 0.6330\n",
            "Epoch 34/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.6639 - acc: 0.7621 - val_loss: 1.0732 - val_acc: 0.6637\n",
            "Epoch 35/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6531 - acc: 0.7673 - val_loss: 1.0389 - val_acc: 0.6546\n",
            "Epoch 36/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.6784 - acc: 0.7578 - val_loss: 1.0651 - val_acc: 0.6610\n",
            "Epoch 37/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6471 - acc: 0.7644 - val_loss: 1.1131 - val_acc: 0.6375\n",
            "Epoch 38/150\n",
            "4435/4435 [==============================] - 2s 415us/step - loss: 0.6482 - acc: 0.7657 - val_loss: 1.1178 - val_acc: 0.6240\n",
            "Epoch 39/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.6371 - acc: 0.7684 - val_loss: 1.1171 - val_acc: 0.6339\n",
            "Epoch 40/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6330 - acc: 0.7747 - val_loss: 1.4203 - val_acc: 0.5708\n",
            "Epoch 41/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6248 - acc: 0.7754 - val_loss: 1.1240 - val_acc: 0.6177\n",
            "Epoch 42/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6228 - acc: 0.7736 - val_loss: 1.0759 - val_acc: 0.6294\n",
            "Epoch 43/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6155 - acc: 0.7770 - val_loss: 1.3070 - val_acc: 0.5870\n",
            "Epoch 44/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.6049 - acc: 0.7766 - val_loss: 1.1577 - val_acc: 0.6249\n",
            "Epoch 45/150\n",
            "4435/4435 [==============================] - 2s 416us/step - loss: 0.6089 - acc: 0.7858 - val_loss: 1.0493 - val_acc: 0.6573\n",
            "Epoch 46/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.6007 - acc: 0.7797 - val_loss: 1.2830 - val_acc: 0.6123\n",
            "Epoch 47/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.5931 - acc: 0.7860 - val_loss: 1.2210 - val_acc: 0.6132\n",
            "Epoch 48/150\n",
            "4435/4435 [==============================] - 2s 423us/step - loss: 0.5979 - acc: 0.7808 - val_loss: 1.1861 - val_acc: 0.6339\n",
            "Epoch 49/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.5840 - acc: 0.7903 - val_loss: 1.0654 - val_acc: 0.6546\n",
            "Epoch 50/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.5860 - acc: 0.7869 - val_loss: 1.3450 - val_acc: 0.5789\n",
            "Epoch 51/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.5670 - acc: 0.8002 - val_loss: 1.0642 - val_acc: 0.6429\n",
            "Epoch 52/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.5662 - acc: 0.7932 - val_loss: 1.1353 - val_acc: 0.6240\n",
            "Epoch 53/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.5400 - acc: 0.8083 - val_loss: 1.0616 - val_acc: 0.6483\n",
            "Epoch 54/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.5517 - acc: 0.7926 - val_loss: 1.1429 - val_acc: 0.6339\n",
            "Epoch 55/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.5428 - acc: 0.8041 - val_loss: 1.0979 - val_acc: 0.6393\n",
            "Epoch 56/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.5288 - acc: 0.8056 - val_loss: 1.1505 - val_acc: 0.6528\n",
            "Epoch 57/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.5220 - acc: 0.8138 - val_loss: 1.1614 - val_acc: 0.6474\n",
            "Epoch 58/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.5202 - acc: 0.8097 - val_loss: 1.1051 - val_acc: 0.6646\n",
            "Epoch 59/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.5170 - acc: 0.8131 - val_loss: 1.1410 - val_acc: 0.6276\n",
            "Epoch 60/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.5083 - acc: 0.8113 - val_loss: 1.1499 - val_acc: 0.6583\n",
            "Epoch 61/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.5238 - acc: 0.8099 - val_loss: 1.1316 - val_acc: 0.6438\n",
            "Epoch 62/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.4933 - acc: 0.8194 - val_loss: 1.1021 - val_acc: 0.6691\n",
            "Epoch 63/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.5058 - acc: 0.8167 - val_loss: 1.2041 - val_acc: 0.6231\n",
            "Epoch 64/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.4960 - acc: 0.8210 - val_loss: 1.1100 - val_acc: 0.6330\n",
            "Epoch 65/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4856 - acc: 0.8244 - val_loss: 1.2581 - val_acc: 0.6087\n",
            "Epoch 66/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.5007 - acc: 0.8167 - val_loss: 1.1497 - val_acc: 0.6610\n",
            "Epoch 67/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.4906 - acc: 0.8212 - val_loss: 1.1427 - val_acc: 0.6628\n",
            "Epoch 68/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.4829 - acc: 0.8250 - val_loss: 1.2073 - val_acc: 0.6357\n",
            "Epoch 69/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4657 - acc: 0.8282 - val_loss: 1.2384 - val_acc: 0.6348\n",
            "Epoch 70/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.4656 - acc: 0.8304 - val_loss: 1.1755 - val_acc: 0.6285\n",
            "Epoch 71/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.4673 - acc: 0.8300 - val_loss: 1.2770 - val_acc: 0.5978\n",
            "Epoch 72/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.4522 - acc: 0.8379 - val_loss: 1.1700 - val_acc: 0.6303\n",
            "Epoch 73/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.4535 - acc: 0.8374 - val_loss: 1.1650 - val_acc: 0.6375\n",
            "Epoch 74/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.4537 - acc: 0.8347 - val_loss: 1.1246 - val_acc: 0.6555\n",
            "Epoch 75/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4459 - acc: 0.8374 - val_loss: 1.1023 - val_acc: 0.6393\n",
            "Epoch 76/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.4243 - acc: 0.8471 - val_loss: 1.1848 - val_acc: 0.6411\n",
            "Epoch 77/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4157 - acc: 0.8487 - val_loss: 1.1979 - val_acc: 0.6519\n",
            "Epoch 78/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.4337 - acc: 0.8410 - val_loss: 1.4219 - val_acc: 0.5636\n",
            "Epoch 79/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4267 - acc: 0.8462 - val_loss: 1.1273 - val_acc: 0.6510\n",
            "Epoch 80/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.4036 - acc: 0.8528 - val_loss: 1.1972 - val_acc: 0.6321\n",
            "Epoch 81/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.4120 - acc: 0.8489 - val_loss: 1.1738 - val_acc: 0.6573\n",
            "Epoch 82/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.4113 - acc: 0.8485 - val_loss: 1.1894 - val_acc: 0.6519\n",
            "Epoch 83/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.4048 - acc: 0.8514 - val_loss: 1.2324 - val_acc: 0.6393\n",
            "Epoch 84/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3921 - acc: 0.8555 - val_loss: 1.1865 - val_acc: 0.6528\n",
            "Epoch 85/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.3938 - acc: 0.8552 - val_loss: 1.1882 - val_acc: 0.6546\n",
            "Epoch 86/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3912 - acc: 0.8582 - val_loss: 1.1553 - val_acc: 0.6682\n",
            "Epoch 87/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3959 - acc: 0.8584 - val_loss: 1.1581 - val_acc: 0.6637\n",
            "Epoch 88/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3781 - acc: 0.8620 - val_loss: 1.1811 - val_acc: 0.6555\n",
            "Epoch 89/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3832 - acc: 0.8658 - val_loss: 1.2309 - val_acc: 0.6610\n",
            "Epoch 90/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3730 - acc: 0.8683 - val_loss: 1.2762 - val_acc: 0.6348\n",
            "Epoch 91/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3714 - acc: 0.8647 - val_loss: 1.3959 - val_acc: 0.6177\n",
            "Epoch 92/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.3791 - acc: 0.8643 - val_loss: 1.1954 - val_acc: 0.6573\n",
            "Epoch 93/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3545 - acc: 0.8706 - val_loss: 1.1667 - val_acc: 0.6682\n",
            "Epoch 94/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3568 - acc: 0.8674 - val_loss: 1.2130 - val_acc: 0.6682\n",
            "Epoch 95/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.3398 - acc: 0.8818 - val_loss: 1.2356 - val_acc: 0.6357\n",
            "Epoch 96/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3405 - acc: 0.8780 - val_loss: 1.2847 - val_acc: 0.6528\n",
            "Epoch 97/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3454 - acc: 0.8755 - val_loss: 1.2320 - val_acc: 0.6375\n",
            "Epoch 98/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3488 - acc: 0.8764 - val_loss: 1.2043 - val_acc: 0.6555\n",
            "Epoch 99/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3330 - acc: 0.8787 - val_loss: 1.2664 - val_acc: 0.6159\n",
            "Epoch 100/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3281 - acc: 0.8787 - val_loss: 1.2927 - val_acc: 0.6159\n",
            "Epoch 101/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.3318 - acc: 0.8776 - val_loss: 1.2987 - val_acc: 0.6168\n",
            "Epoch 102/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.3279 - acc: 0.8803 - val_loss: 1.2061 - val_acc: 0.6691\n",
            "Epoch 103/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3308 - acc: 0.8753 - val_loss: 1.3111 - val_acc: 0.6501\n",
            "Epoch 104/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.3125 - acc: 0.8875 - val_loss: 1.2516 - val_acc: 0.6573\n",
            "Epoch 105/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3106 - acc: 0.8859 - val_loss: 1.2513 - val_acc: 0.6411\n",
            "Epoch 106/150\n",
            "4435/4435 [==============================] - 2s 417us/step - loss: 0.2925 - acc: 0.8952 - val_loss: 1.2259 - val_acc: 0.6745\n",
            "Epoch 107/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3002 - acc: 0.8888 - val_loss: 1.3381 - val_acc: 0.6519\n",
            "Epoch 108/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.3089 - acc: 0.8933 - val_loss: 1.3858 - val_acc: 0.6330\n",
            "Epoch 109/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2896 - acc: 0.8988 - val_loss: 1.2731 - val_acc: 0.6564\n",
            "Epoch 110/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2869 - acc: 0.9001 - val_loss: 1.2274 - val_acc: 0.6610\n",
            "Epoch 111/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.2845 - acc: 0.8972 - val_loss: 1.2438 - val_acc: 0.6501\n",
            "Epoch 112/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.2798 - acc: 0.9008 - val_loss: 1.2941 - val_acc: 0.6519\n",
            "Epoch 113/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.3052 - acc: 0.8877 - val_loss: 1.4031 - val_acc: 0.6123\n",
            "Epoch 114/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2752 - acc: 0.9006 - val_loss: 1.2339 - val_acc: 0.6619\n",
            "Epoch 115/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2743 - acc: 0.8985 - val_loss: 1.3946 - val_acc: 0.6537\n",
            "Epoch 116/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2750 - acc: 0.9019 - val_loss: 1.3463 - val_acc: 0.6312\n",
            "Epoch 117/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.2866 - acc: 0.8972 - val_loss: 1.3603 - val_acc: 0.6384\n",
            "Epoch 118/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2683 - acc: 0.9053 - val_loss: 1.3134 - val_acc: 0.6519\n",
            "Epoch 119/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2649 - acc: 0.9046 - val_loss: 1.3533 - val_acc: 0.6573\n",
            "Epoch 120/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2558 - acc: 0.9089 - val_loss: 1.2937 - val_acc: 0.6429\n",
            "Epoch 121/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2556 - acc: 0.9109 - val_loss: 1.3305 - val_acc: 0.6519\n",
            "Epoch 122/150\n",
            "4435/4435 [==============================] - 2s 423us/step - loss: 0.2496 - acc: 0.9116 - val_loss: 1.5404 - val_acc: 0.6258\n",
            "Epoch 123/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.2689 - acc: 0.9024 - val_loss: 1.3833 - val_acc: 0.6564\n",
            "Epoch 124/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2544 - acc: 0.9105 - val_loss: 1.4379 - val_acc: 0.6294\n",
            "Epoch 125/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2432 - acc: 0.9163 - val_loss: 1.3119 - val_acc: 0.6528\n",
            "Epoch 126/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2442 - acc: 0.9100 - val_loss: 1.3823 - val_acc: 0.6213\n",
            "Epoch 127/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2576 - acc: 0.9094 - val_loss: 1.3103 - val_acc: 0.6592\n",
            "Epoch 128/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.2364 - acc: 0.9132 - val_loss: 1.3439 - val_acc: 0.6655\n",
            "Epoch 129/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2320 - acc: 0.9195 - val_loss: 1.3593 - val_acc: 0.6294\n",
            "Epoch 130/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.2418 - acc: 0.9114 - val_loss: 1.3298 - val_acc: 0.6610\n",
            "Epoch 131/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2304 - acc: 0.9152 - val_loss: 1.5309 - val_acc: 0.6393\n",
            "Epoch 132/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.2392 - acc: 0.9112 - val_loss: 1.3615 - val_acc: 0.6465\n",
            "Epoch 133/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2322 - acc: 0.9209 - val_loss: 1.7069 - val_acc: 0.6069\n",
            "Epoch 134/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2340 - acc: 0.9175 - val_loss: 1.3491 - val_acc: 0.6483\n",
            "Epoch 135/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2214 - acc: 0.9195 - val_loss: 1.5528 - val_acc: 0.6050\n",
            "Epoch 136/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2268 - acc: 0.9213 - val_loss: 1.3346 - val_acc: 0.6601\n",
            "Epoch 137/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2081 - acc: 0.9258 - val_loss: 1.4413 - val_acc: 0.6501\n",
            "Epoch 138/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.2088 - acc: 0.9265 - val_loss: 1.5090 - val_acc: 0.6303\n",
            "Epoch 139/150\n",
            "4435/4435 [==============================] - 2s 422us/step - loss: 0.2078 - acc: 0.9263 - val_loss: 1.5205 - val_acc: 0.6375\n",
            "Epoch 140/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2179 - acc: 0.9236 - val_loss: 1.3713 - val_acc: 0.6411\n",
            "Epoch 141/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.2182 - acc: 0.9224 - val_loss: 1.4021 - val_acc: 0.6583\n",
            "Epoch 142/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.1997 - acc: 0.9272 - val_loss: 1.4336 - val_acc: 0.6610\n",
            "Epoch 143/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.2068 - acc: 0.9258 - val_loss: 1.3633 - val_acc: 0.6393\n",
            "Epoch 144/150\n",
            "4435/4435 [==============================] - 2s 421us/step - loss: 0.1930 - acc: 0.9301 - val_loss: 1.4646 - val_acc: 0.6555\n",
            "Epoch 145/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.1997 - acc: 0.9263 - val_loss: 1.4068 - val_acc: 0.6501\n",
            "Epoch 146/150\n",
            "4435/4435 [==============================] - 2s 420us/step - loss: 0.1790 - acc: 0.9348 - val_loss: 1.4715 - val_acc: 0.6691\n",
            "Epoch 147/150\n",
            "4435/4435 [==============================] - 2s 418us/step - loss: 0.1734 - acc: 0.9348 - val_loss: 1.4407 - val_acc: 0.6655\n",
            "Epoch 148/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.1818 - acc: 0.9364 - val_loss: 1.4707 - val_acc: 0.6213\n",
            "Epoch 149/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.1932 - acc: 0.9317 - val_loss: 1.4252 - val_acc: 0.6375\n",
            "Epoch 150/150\n",
            "4435/4435 [==============================] - 2s 419us/step - loss: 0.1824 - acc: 0.9389 - val_loss: 1.4107 - val_acc: 0.6664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1a0ac1588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPzhPCUy7WzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_images(directory):\n",
        "    Images = []\n",
        "    Image_names = []\n",
        "    for image_file in os.listdir(directory):\n",
        "        Image_names.append(image_file)\n",
        "        image = cv2.imread(directory+r'/'+image_file)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image,(51,51),)\n",
        "            Images.append(image)\n",
        "    return Images, Image_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMv1C13sFA3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9292a43-440d-480c-c5b3-c8f1caf02323"
      },
      "source": [
        "test_images, image_names = get_test_images('../tmp/test/')\n",
        "test_images = np.array(test_images)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(794, 51, 51, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnVB89a1GAcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8418cd69-1416-4548-adb8-5693e86e4ec7"
      },
      "source": [
        "predictions = model.predict(test_images)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "predictions.shape"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(794,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByLfED_0Mg8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelled_predictions = []\n",
        "mapping = {0: 'Sugar beet',1:'Fat Hen' ,2: 'Scentless Mayweed',3:  'Charlock', \n",
        "        4:'Small-flowered Cranesbill', 5:'Maize' ,\n",
        "        6: 'Shepherds Purse' ,7:'Common wheat' ,8:'Common Chickweed' ,\n",
        "        9:'Cleavers' ,10:'Loose Silky-bent'  ,11: 'Black-grass'}\n",
        "for pred in predictions:\n",
        "    if pred==12 or pred==0 or pred==10:\n",
        "        continue  \n",
        "    labelled_predictions.append(mapping[pred])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWonfZg4QJB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWdhAqm_M4Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelled_predictions = np.array(labelled_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGkthoh9FGtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95c8fab5-9da3-4d8e-d77a-fbf5a9366abc"
      },
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "# Print test accuracy\n",
        "print('\\n', 'Train accuracy:', score[1])"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Train accuracy: 0.9652762118831966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W93RFkQVF6PR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "362182b1-94f5-45b2-c859-860de88d120d"
      },
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_val,y_val, verbose=0)\n",
        "# Print test accuracy\n",
        "print('\\n', 'Validation accuracy:', score[1])"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Validation accuracy: 0.6663660959578291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cX716CxKGmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}